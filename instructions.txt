A continuación presento un análisis exhaustivo de lo que ya existe en el repositorio, los puntos débiles o faltantes, las piezas que hacen falta implementar y, finalmente, un plan paso a paso para llegar a un agente coherente, operativo y capaz de mantener memoria de usuario. No hay concesiones: cada sección describe con claridad qué hay, qué falta y cómo avanzar.

⸻

1. Revisión de la arquitectura y el código actual

1.1 Estructura de carpetas y componentes principales
	•	src/agent/interfaces/whatsapp/
	•	webhook_endpoint.py (FastAPI). Expone un endpoint que recibe los eventos de WhatsApp (texto, audio, imagen).
	•	whatsapp_response.py. Procesa el JSON entrante de Meta Cloud API, extrae número de origen, descarga audio o imagen si aplica, crea un HumanMessage, crea un grafo y pasa el estado a LangGraph con un checkpointer de PostgreSQL, luego envía la respuesta via HTTP a la API de WhatsApp.
	•	src/agent/graph/
	•	graph.py. Define la función create_workflow_graph() que construye el grafo de nodos de LangGraph:
	•	Nodos de extracción e inyección de memoria.
	•	Nodos de enrutamiento (router_node selecciona si sigue flujo de texto, imagen o audio).
	•	Nodos de conversación (conversation_node), de imagen (image_node), de audio (audio_node).
	•	Nodos de resumen (summarize_conversation_node).
	•	nodes.py. Implementa cada nodo:
	•	memory_extraction_node: recibe el último mensaje, lo envía a MemoryManager para analizar si debe guardarlo.
	•	memory_injection_node: extrae del vector store (Qdrant) los recuerdos relevantes basados en los últimos mensajes para inyectarlos en el “character card” o prompt.
	•	context_injection_node: inyecta el contexto de programación diaria (“current_activity”) y el resumen si aplica.
	•	conversation_node, image_node, audio_node: cada uno se encarga de invocar la cadena de Groq/LLM adecuada para generar la respuesta según tipo de mensaje y renderizar TTS/TI si es necesario.
	•	edges.py. Contiene las condiciones que separan el flujo:
	•	select_workflow: decide “conversation”, “image” o “audio” según estado.
	•	should_summarize_conversation: si el historial excede cierto número de mensajes, envía a resumen.
	•	src/agent/modules/memory/long_term/
	•	memory_manager.py. Orquesta el análisis de un mensaje (mediante un prompt de LLM) para determinar si es “útil” como recuerdo. Si lo es, calcula embeddings usando un modelo de SentenceTransformer, comprueba duplicados en Qdrant (vía find_similar_memory) y si no existe, lo almacena con metadata (ID, timestamp).
	•	vector_store.py. Encapsula la conexión con Qdrant:
	•	Inicializa SentenceTransformer con el modelo definido en variables de entorno.
	•	Crea la colección en Qdrant (si no existe) con tamaño de vector determinado.
	•	Métodos para store_memory(text, metadata) que codifica texto, genera PointStruct y hace upsert.
	•	Métodos para find_similar_memory(text) y search_memories(query, top_k) que devuelven vecinos semánticos.
	•	src/agent/core/database.py
	•	get_checkpointer(). Devuelve un AsyncPostgresSaver configurado con la URL de PostgreSQL (variable DATABASE_URL). Usa langgraph.checkpoint.postgres.aio para persistir el estado del grafo (mensajes, variables de estado, checkpointer interno).
	•	Función de prueba de la conexión.
	•	src/agent/settings.py
	•	Todos los valores de entorno (API keys, URLs, nombres de modelo).
	•	Parámetros de configuración (número de mensajes para disparar resumen, modelo de LLM, parámetros top k de memoria).
	•	Archivos de configuración generales
	•	Dockerfile, docker-compose.yml y cloudbuild.yaml para desplegar en Cloud Run/CI.
	•	langgraph.json: debería apuntar al grafo principal, pero referencia un path que no coincide con la ubicación real (se menciona src/ai_companion/graph/graph.py, pero en realidad el grafo está en src/agent/graph/graph.py). Ese desalineamiento se debe corregir o actualizarnos para que LangGraph Studio lo encuentre.
	•	Archivos de tests: test_connections.py y test_postgres_checkpointer.py. Verifican conectividad con Qdrant y PostgreSQL, pero no cubren casos de extremo a extremo o de lógica de memoria.

1.2 Flujo de ejecución resumido
	1.	Un mensaje llega a FastAPI: /webhook recibe el evento de WhatsApp.
	2.	Extrae el contenido (texto, audio → transcrito, imagen → descripción).
	3.	Abre un contexto async with get_checkpointer() as checkpointer: y hace graph = graph_builder.compile(checkpointer=checkpointer).
	4.	Alimenta el HumanMessage(content=…) inicial al grafo con estado vacío o retomado si hay un estado previo para ese número (el session_id es el número de teléfono).
	5.	El grafo recorre nodos:
	•	memory_extraction_node: analiza el último mensaje y, si hay fragmento de valor (“frase importante”), lo guarda en Qdrant.
	•	router_node: examina state["workflow"] (determinado por patrones en el context_injection_node o por formato del mensaje) y selecciona si el flujo sigue a conversación, imagen o audio.
	•	context_injection_node: inyecta el resumen del día y actividad actual, lo que mantiene el contexto de rutina de aprendizaje.
	•	memory_injection_node: hace una búsqueda semántica en Qdrant con los últimos 3 mensajes, recupera memorias relevantes, formatea como viñetas y las añade a las metas del prompt.
	•	conversation_node / image_node / audio_node: llama a Groq para generar un mensaje de respuesta. Si es voz o imagen, genera TTS o imagen.
	•	summarize_conversation_node (si se activa): agrupa los últimos X mensajes en un resumen y lo almacena en state["summary"].
	6.	El grafo retorna un AIMessage con el contenido a enviar.
	7.	Por último, FastAPI envía ese AIMessage a través de la API de WhatsApp (texto/payload de audio/imagen).

1.3 Fortalezas de la implementación actual
	•	Separación clara de responsabilidades:
	•	El código de FastAPI sólo maneja I/O con WhatsApp.
	•	El grafo de LangGraph está aislado en src/agent/graph.
	•	La lógica de memoria de largo plazo (análisis + vector store) está encapsulada en MemoryManager y VectorStore.
	•	Persistencia del estado del grafo: gracias al AsyncPostgresSaver, cada interacción queda registrada en PostgreSQL, lo que permite retomar conversaciones largas, hacer auditoría y depurar.
	•	Uso de Qdrant con embeddings: la memoria no se limita a texto puro, sino a embeddings semánticos que permiten rescatar fragmentos relevantes aunque no coincidan literalmente.
	•	Soporte multi-modal: texto, audio (STT/TTS) e imagen (image-to-text + generación si corresponde).
	•	Configuración basada en variables de entorno: todos los endpoints, claves y configuraciones de modelo están centralizados en settings.py y .env.
	•	Docker y CI preparados: hay Dockerfile, docker-compose.yml y cloudbuild.yaml listos para escalar o desplegar en Cloud Run.

1.4 Puntos débiles o inconsistencias detectadas
	1.	langgraph.json desactualizado
	•	Actualmente referencia un path src/ai_companion/graph/graph.py:graph, pero el grafo real está en src/agent/graph/graph.py. Hay que corregir esa ruta, de lo contrario no podrá usarse LangGraph Studio ni el comando lg compile.
	2.	No hay gestión de usuarios en PostgreSQL
	•	Se utiliza el número de teléfono como session_id, pero no existe una tabla relacional de “usuarios”. El repositorio no crea la tabla users ni sessions ni messages en PostgreSQL para fines de logging o de aprendizaje.
	•	El checkpointer de LangGraph persiste automáticamente el estado del grafo (mensajes, variables), pero no hay una base de datos relacional explícita donde almacenar información de progreso del aprendizaje (vocabulario, gramática, niveles). Eso se echa en falta para medir desempeño o personalizar el plan educativo.
	3.	Falta de tablas para estadísticas de usuario
	•	No hay un esquema relacional que registre métricas de aprendizaje (número de palabras nuevas, errores de gramática, horas de práctica). Sería recomendable diseñar un esquema de “learning_stats” o similar para almacenarlo junto a cada usuario.
	4.	No existe un servicio explícito que gestione “niveles” o “planes de estudio”
	•	El grafo inyecta “current_activity” (definida por ScheduleContextGenerator) y un resumen, pero no hay lógica que ajuste el contenido pedagógico según el nivel (A1, A2, B1, etc.) del estudiante. Tampoco existe un módulo que corrija errores gramaticales y registre dichas correcciones por usuario.
	5.	Pruebas automáticas insuficientes
	•	Existen dos tests básicos: conexión a la base de datos y checkpointer. No hay pruebas de extremo a extremo para simular la llegada de un mensaje de WhatsApp y verificar que se almacene la memoria, se recupere el contexto y se genere una respuesta coherente.
	•	No hay validaciones de manejo de errores (por ejemplo: qué pasa si Qdrant no responde, si la clave de ElevenLabs es inválida, o si el modelo Groq falla).
	6.	Dependencia en modelos locales para embeddings
	•	SentenceTransformer se usa en vector_store.py. Eso puede encarecer memory_extraction_node si no se cuenta con GPU o si el modelo es pesado. Sería conveniente considerar un servicio de embeddings externo (OpenAI embeddings) para aligerar carga en producción o un microservicio de embeddings.
	7.	Gestión de versiones de modelos y coherencia de prompt
	•	MEMORY_ANALYSIS_PROMPT, cadenas de get_character_response_chain y get_router_chain están en archivos de prompts, pero no hay documentación clara de qué contienen esos prompts ni cómo afectan la personalización educativa.
	•	Tampoco se versiona explícitamente el prompt de “análisis de memoria” para que uno sepa qué criterios usa Groq para decidir si guardar un fragmento.
	8.	No hay esquema de control de sesiones largas / token-limites
	•	Actualmente, se hace un resumen automático cada TOTAL_MESSAGES_SUMMARY_TRIGGER (20 por defecto) y se retiene un resumen breve de los últimos cinco mensajes tras eso. Pero no hay un mecanismo que reduzca sistemáticamente el tamaño del prompt si la conversación crece a cientos de intercambios. Sin un manejo explícito de token-limit, el grafo podría fallear por exceder tamaño de contexto.
	9.	Falta de sincronización explícita entre PostgreSQL y Qdrant
	•	Si bien la memoria extraída se guarda en Qdrant, no hay un puente que registre en Postgres que “esta memoria perteneció a este usuario en tal sesión”. La metadata que se almacena en Qdrant incluye id, timestamp y text, pero no el user_id ni session_id. Eso dificulta auditorías o limpieza de memoria histórica (e.g., eliminar datos de un usuario si exige GDPR).
	10.	Ambigüedad en el manejo de errores de WhatsApp
	•	En whatsapp_response.py, si send_response falla, retorna un error HTTP 500, pero no hay reintentos ni logging diferenciado para cada tipo de falla (por límite de WhatsApp, número bloqueado, falta de crédito, etc.).

⸻

2. Qué debemos crear o mejorar

A partir de los puntos débiles identificados, enumero a continuación las piezas que hacen falta implementar, corregir o reforzar:

2.1 Corregir rutas y archivos de configuración
	1.	Actualizar langgraph.json para que apunte a src/agent/graph/graph.py:graph (en lugar de src/ai_companion/graph/graph.py:graph).
	2.	Revisar pyproject.toml y asegurarse de que las dependencias de LangGraph, Qdrant, SentenceTransformer, LangChain y Groq estén correctamente listadas y en versiones compatibles.

2.2 Esquema relacional en PostgreSQL para usuarios y métricas
	1.	Diseñar tablas explícitas:
	•	users (id UUID PK, phone_number TEXT unique, name TEXT, current_level TEXT, created_at TIMESTAMPTZ)
	•	sessions (id UUID PK, user_id UUID FK, started_at TIMESTAMPTZ, ended_at TIMESTAMPTZ, context JSONB)
	•	messages (id UUID PK, session_id UUID FK, sender TEXT, message TEXT, timestamp TIMESTAMPTZ)
	•	learning_stats (id UUID PK, user_id UUID FK, vocab_learned TEXT[], grammar_issues JSONB, last_updated TIMESTAMPTZ)
	2.	Modificar get_checkpointer() para que, además de persistir el estado de LangGraph, guarde cada mensaje en la tabla messages y, si es la primera interacción, inserte un registro en users con el phone_number→user_id.
	3.	Crear un módulo agent/core/models.py o similar con las clases Pydantic/SQLAlchemy que representen esas tablas para facilitar inyecciones directas de estadístias.

2.3 Ampliar el MemoryManager y VectorStore
	1.	Agregar metadata a cada memoria:
	•	Asegurarse de que al llamar a vector_store.store_memory(...) incluyamos user_id y session_id como parte de payload. Eso permitirá filtrar búsquedas por usuario o sesión.
	•	Cambiar la firma de store_memory(text, metadata) para recibir user_id, session_id, timestamp explícitamente.
	2.	Crear endpoints o scripts para limpieza/expurgo de memorias antiguas si el usuario borra su cuenta o quiere reiniciar su progreso.
	3.	Agregar un método de “garbage collection” que revise en Qdrant los vectores con fecha muy antigua y los elimine, o los archive en otra tabla en Postgres.

2.4 Lógica de progresión pedagógica
	1.	Módulo que defina niveles (A1–C1):
	•	Crear en src/agent/modules/learning/ un archivo curriculum.py que contenga las descripciones de actividades, vocabulario objetivo y métricas para cada nivel.
	•	En el nodo context_injection_node, extraer de learning_stats.current_level y añadir instrucciones al prompt para que la respuesta se adapte al nivel. Ejemplo: “You are talking to a user at level A1; use basic sentences.”
	2.	Registro de errores gramaticales:
	•	Implementar en MemoryAnalysis un análisis que, aparte de decidir si guardar un fragmento completo, detecte los errores frecuentes (p. ej., conjugaciones, tiempos verbales) y añada un campo a grammar_issues.
	•	Al final de cada sesión, programar un resumen de “errores más comunes” y, en el siguiente mensaje, recomendar ejercicios enfocados.

2.5 Optimización del manejo de estados y límites de contexto
	1.	Refactorizar should_summarize_conversation para que resuma no sólo por número de mensajes, sino también por longitud total de tokens (extraer con LangChain una estimación de tokens).
	2.	Implementar un nodo adicional que recorte la lista de mensajes antiguos > X tokens y solo conserve los últimos fragmentos y el resumen general.

2.6 Pruebas end-to-end y manejo de errores
	1.	Escribir tests de integración que:
	•	Simulen la llegada de un mensaje de texto a través de FastAPI.
	•	Verifiquen que: la tabla users se crea, la conversación se persiste, la memoria (si la hay) se almacena en Qdrant y la respuesta es la esperada (puede ser un mock de Groq o un LLM dummy).
	2.	Agregar logging granular en cada nodo para poder detectar cuándo falla la extracción de memoria, cuándo falla TTS/TI o cuándo la llamada a WhatsApp no regresa 200.
	3.	Crear un middleware en FastAPI para interceptar y manejar excepciones genéricas: timeouts de Qdrant, timeouts de WhatsApp, credenciales incorrectas. Devuelve un mensaje de texto genérico al usuario como fallback (“Lo siento, ocurrió un error interno. Intentemos más tarde.”).

2.7 Opcional: migrar embeddings a un servicio externo
	1.	Evaluar usar las embeddings de OpenAI en lugar de SentenceTransformer local para aligerar el peso de memoria del contenedor. Crear un adaptador en vector_store que pueda alternar entre “local” y “openai” según una variable de entorno EMBEDDING_PROVIDER=local|openai.
	2.	Si se opta por OpenAI, modificar find_similar_memory y store_memory para:
	•	vector = openai.Embeddings.create(input=text, model="text-embedding-3-small").
	•	Guardar igual en Qdrant, pero sin dependencia de librería pesada de SentenceTransformer.

⸻

3. Plan de acción paso a paso

Paso 0. Preparación inicial y correcciones inevitables
	1.	Abrir langgraph.json y corregir la ruta al grafo:
	•	Cambiar "graphs": { "agent": "./src/ai_companion/graph/graph.py:graph" }
	•	Por   "graphs": { "agent": "./src/agent/graph/graph.py:graph" }
	2.	Verificar .env:
	•	Asegurarse de que existan las claves:
	•	DATABASE_URL → URL de PostgreSQL
	•	QDRANT_URL, QDRANT_API_KEY → para vector store
	•	GROQ_API_KEY, ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID
	•	WHATSAPP_TOKEN, WHATSAPP_PHONE_NUMBER_ID
	•	Cualquier otro modelo que use Groq o Meta
	•	Probar python src/agent/core/database.py para asegurar que el checkpointer se conecta sin errores.

⸻

Paso 1. Crear y poblar esquema relacional en PostgreSQL
	1.	Escribir un script SQL inicial (por ejemplo, scripts/init_db.sql) con el siguiente contenido:

-- 1. Tabla de usuarios
CREATE TABLE IF NOT EXISTS users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    phone_number TEXT UNIQUE NOT NULL,
    name TEXT,
    current_level TEXT DEFAULT 'A1',
    created_at TIMESTAMPTZ DEFAULT now()
);

-- 2. Tabla de sesiones
CREATE TABLE IF NOT EXISTS sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    started_at TIMESTAMPTZ DEFAULT now(),
    ended_at TIMESTAMPTZ,
    context JSONB
);

-- 3. Tabla de mensajes
CREATE TABLE IF NOT EXISTS messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID REFERENCES sessions(id),
    sender TEXT CHECK (sender IN ('user', 'agent')),
    message TEXT NOT NULL,
    timestamp TIMESTAMPTZ DEFAULT now()
);

-- 4. Tabla de estadísticas de aprendizaje
CREATE TABLE IF NOT EXISTS learning_stats (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    vocab_learned TEXT[],
    grammar_issues JSONB,
    last_updated TIMESTAMPTZ DEFAULT now()
);


	2.	Ejecutar psql contra su instancia de PostgreSQL para validar que las tablas se crean correctamente.
	3.	Modificar agent/core/database.py:
	•	Después de hacer checkpointer = await AsyncPostgresSaver(...), pero ANTES de retornar el checkpointer, inyectar lógica para que, cuando llegue un session_id (teléfono), revise si existe un users.phone_number = session_id; si no existe, insertar en users y guardar user_id.
	•	Crear o actualizar el registro de sessions para esa llamada (nueva si no existe, o retomar si hay una sesión activa sin ended_at).
	•	Para cada mensaje entrante (antes de pasarlo al grafo), insertar un registro en messages(session_id, sender='user', message=texto, timestamp=now()). Y, una vez salga la respuesta del grafo, insertar messages(session_id, sender='agent', message=respuesta, timestamp=now()).
Ejemplo simplificado (pseudocódigo en Python):

async def get_checkpointer():
    global _setup_done
    if not _setup_done:
        # crear tablas de LangGraph si no existen
        saver = AsyncPostgresSaver(...)
        await saver.setup()
        _setup_done = True

    # Conectar a DB para manejar usuarios y sesiones
    db = await asyncpg.connect(os.getenv("DATABASE_URL"))
    async def _wrapped_checkpointer():
        session_id = state["session_id"]  # obtenido en webhook
        # 1) Revisar o crear user
        user = await db.fetchrow("SELECT id FROM users WHERE phone_number = $1", session_id)
        if not user:
            user_id = await db.fetchval("INSERT INTO users (phone_number) VALUES ($1) RETURNING id", session_id)
        else:
            user_id = user["id"]
        state["user_id"] = user_id

        # 2) Revisar o crear session
        session = await db.fetchrow("SELECT id FROM sessions WHERE user_id = $1 AND ended_at IS NULL", user_id)
        if not session:
            session_id_db = await db.fetchval("INSERT INTO sessions (user_id) VALUES ($1) RETURNING id", user_id)
        else:
            session_id_db = session["id"]
        state["db_session_id"] = session_id_db

        return saver
    return await _wrapped_checkpointer()


	4.	Actualizar whatsapp_response.py:
	•	Justo después de content = message["text"]["body"], y antes de llamar al grafo, invocar un helper para registrar en la tabla messages el mensaje del usuario.
	•	Después de generar response_message, insertar otro registro con sender='agent' y message=response_message.

⸻

Paso 2. Integrar metadata de usuario en Qdrant para memoria
	1.	Modificar agent/modules/memory/long_term/vector_store.py:
	•	En el método store_memory, añadir parámetros user_id y session_id y guardarlos en el payload. Por ejemplo:

point = PointStruct(
    id=metadata.get("id", hash(text)),
    vector=embedding.tolist(),
    payload={
        "text": text,
        "user_id": metadata["user_id"],
        "session_id": metadata["session_id"],
        "timestamp": metadata["timestamp"],
    },
)


	•	Actualizar todas las llamadas a store_memory en MemoryManager para pasar estos datos:

await self.vector_store.store_memory(
    text=analysis.formatted_memory,
    metadata={
        "id": str(uuid.uuid4()),
        "timestamp": datetime.now().isoformat(),
        "user_id": state["user_id"],
        "session_id": state["db_session_id"],
    },
)


	2.	En get_memory_manager.extract_and_store_memories, asegurarse de que state (o se pase como argumento) contenga user_id y session_id para que se envíe correctamente. Actualmente usa message, pero no sabe a qué usuario pertenece. Debe refactorizarse para que reciba tanto message como state["user_id"] y state["db_session_id"].
	3.	Actualizar get_relevant_memories para que filtre por user_id. Ejemplo:

def get_relevant_memories(self, context: str, user_id: str) -> List[str]:
    # llame a Qdrant.search con un filter que incluya {"key": "user_id", "match": {"value": user_id}}
    results = self.client.search(
        collection_name=self.COLLECTION_NAME,
        query_vector=embedding_context,
        limit=settings.MEMORY_TOP_K,
        filter={"must": [{"key": "user_id", "match": {"value": user_id}}]},
    )
    # retornar [m.payload["text"] for m in results]


	4.	Ajustar memory_injection_node para que llame a get_relevant_memories(recent_context, state["user_id"]) y no solamente a get_relevant_memories(recent_context).

⸻

Paso 3. Añadir lógica de progresión de aprendizaje y métricas
	1.	Crear módulo src/agent/modules/learning/curriculum.py con un diccionario que describa para cada nivel (A1, A2, B1, …) el vocabulario objetivo, tipos de ejercicios y métricas. Ejemplo:

CURRICULUM = {
    "A1": {
        "description": "Usuario principiante: oraciones simples, vocabulario básico.",
        "target_vocab": ["hello", "book", "apple", ...],
        "grammar_focus": ["to be", "simple present"],
    },
    "A2": { ... },
    ...
}


	2.	Modificar context_injection_node: además de inyectar current_activity, extraer state["user_id"], luego consultar la tabla learning_stats para saber current_level. Por defecto usa A1 si no existe.
	•	Añadir al prompt:

The learner is at level {current_level}. Base your response in accordance with this level's curriculum: {CURRICULUM[current_level]}.


	3.	Registrar diariamente métricas:
	•	Después de cada conversación, o tras el nodo conversation_node, agregar un nuevo nodo opcional llamado update_learning_stats_node. Este nodo haría algo como:

async def update_learning_stats_node(state):
    # analizar últimos mensajes del usuario para detectar vocabulario nuevo
    new_words = extract_new_words(state["messages"], state["learning_stats"].vocab_learned)
    # corregir errores via un LLM o una librería de gramática
    errors = detect_grammar_errors(state["messages"][-1].content)
    # actualizar la tabla learning_stats en PostgreSQL
    await db.execute(
        "UPDATE learning_stats SET vocab_learned = array_cat(vocab_learned, $1), grammar_issues = $2, last_updated = now() WHERE user_id = $3",
        new_words, errors, state["user_id"]
    )
    return {}


	•	Y enlazar ese nodo justo después de conversation_node con una arista condicional (si el mensaje fue de tipo texto).

⸻

Paso 4. Mejorar manejo de resumen y contexto largo
	1.	Refactorizar should_summarize_conversation: que reciba también un límite de tokens. Usar LangChain para estimar cuántos tokens pesan los state["messages"]. Si exceden, disparar resumen.

from langchain_core.schema import BaseMessage
from langchain_core.token_counter import count_tokens
async def should_summarize_conversation(state):
    total_tokens = sum(count_tokens(m.content) for m in state["messages"])
    if total_tokens > settings.MAX_TOKENS_THRESHOLD:
        return "summarize_conversation_node"
    return END


	2.	Crear un nodo prune_old_messages_node: si la conversación es demasiado larga, eliminar de state["messages"] los primeros N mensajes que ya aparecen en el resumen.
	•	Este nodo se invoca justo después de summarize_conversation_node.
	•	Conserve en state["messages"] sólo:
	1.	El mensaje del resumen final (tipo AIMessage),
	2.	Los últimos settings.TOTAL_MESSAGES_AFTER_SUMMARY mensajes humanos.

⸻

Paso 5. Desarrollar pruebas end-to-end y manejo de errores
	1.	Crear tests en tests/test_whatsapp_integration.py: usar httpx.AsyncClient para simular un POST con JSON de ejemplo de WhatsApp, verificar que:
	•	Devuelve 200 (“Message processed”).
	•	Se inserta un registro en users y sessions.
	•	Para un mensaje de texto, se llama a graph_builder.compile(...), se invoca el grafo con un LLM “mock” (puede usarse LangChain con un modelo fake en tests) y se comprueba que messages en state incluyan la respuesta.
	2.	Tests de memoria: en tests/test_memory_manager.py, inyectar un texto que contenga una frase de valor, verificar que:
	•	Almacene un punto en Qdrant con metadata correcta.
	•	Si se vuelve a enviar el mismo fragmento, no duplique (prueba de find_similar_memory).
	3.	Manejo de excepciones:
	•	En whatsapp_response.py, envolver el bloque de envío de respuesta en un try/except más granular:

try:
    success = await send_response(...)
except httpx.HTTPStatusError as exc:
    logger.error(f"WhatsApp API error: {exc.response.status_code} - {exc.response.text}")
    # opcional: encolar la respuesta para reintento o guardar en un log para reintento offline
    return Response(content="Failed to send message", status_code=502)
except Exception as exc:
    logger.error(f"Unknown error sending to WhatsApp: {exc}", exc_info=True)
    return Response(content="Internal server error", status_code=500)


	•	Registrar en un log separado (errors.log) cualquier falla de Qdrant o Groq. En MemoryManager.extract_and_store_memories, envolver la llamada a Groq dentro de try/except para que, si falla, solo haga self.logger.warning(...) pero no detenga el flujo.

⸻

Paso 6. Documentar flujos y prompts
	1.	Crear un documento docs/architecture.md que describa de forma breve pero contundente:
	•	Diagrama de componentes (WhatsApp → FastAPI → LangGraph → Qdrant + PostgreSQL → Groq/ElevenLabs).
	•	Definición de cada tabla del esquema relacional.
	•	Explicación de cada nodo clave en el grafo.
	2.	Revisar todos los prompts en src/agent/core/prompts.py y documentar para qué sirve cada uno, qué variables recibe y un ejemplo de cómo se ve.
	3.	Incluir ejemplos de JSON de request/respuesta en docs/swagger_examples.json o directamente en README.md (secciones de “Para desarrolladores”).

⸻

Paso 7. Despliegue y validación en un entorno de staging
	1.	Actualizar Dockerfile para que instale el paquete sentence-transformers (u otra librería de embeddings) y configure la versión de Python 3.12 como en pyproject.toml.
	2.	Agregar al docker-compose.yml:
	•	Un servicio postgres (imagen oficial, volúmenes persistentes).
	•	Un servicio qdrant (imagen oficial, volúmenes persistentes).
	•	Opcionalmente, un contenedor groq-emulator si quieren mockear local el servicio Groq.
	3.	Levantar localmente con docker-compose up, corroborar:
	•	Que el endpoint /webhook en http://localhost:8000/ responda.
	•	Que, enviando un JSON simulado de WhatsApp, aparezca la conversación en la terminal y se inserten datos en Postgres y Qdrant.
	•	Que el LLM real devuelva contenido adecuado (pueden usar el entorno de test con un modelo dummy).

⸻

Paso 8. Refinamiento de UX educativo y métricas finales
	1.	Implementar un nodo final opcional llamado feedback_request_node: después de X interacciones, invitar al usuario a evaluar su satisfacción (“¿Te ha resultado útil esta conversación?”). Registrar esa respuesta en learning_stats o en una tabla adicional user_feedback.
	2.	Verificar que cada usuario reciba un mensaje de bienvenida la primera vez que interactúe (“Hola, soy Joi. ¿En qué nivel estás? A1, A2, B1…”). Para implementarlo:
	•	Modificar whatsapp_response.py: si session_id no tiene sessions previas (la consulta retorna None), enviar un mensaje estático de bienvenida antes de invocar el grafo.
	3.	Crear un dashboard sencillo en Flask o Streamlit (opcional) para visualizar:
	•	Número de usuarios activos.
	•	Métricas de aprendizaje (vocabulario aprendido, nivel actual).
	•	Puntos de memoria más consultados (top 10 por usuario).

⸻

4. Resumen de los pasos críticos y ordenados
	1.	Corregir rutas en langgraph.json → validar con lg compile.
	2.	Inicializar y poblar el esquema relacional en PostgreSQL (tablas: users, sessions, messages, learning_stats).
	3.	Refactorizar get_checkpointer() para:
	•	Crear/recuperar user_id (tabla users) según session_id (teléfono).
	•	Crear/recuperar session_id_db (tabla sessions).
	•	Configurar state["user_id"] y state["db_session_id"] antes de devolver el checkpointer.
	4.	En whatsapp_response.py:
	•	Insertar en tabla messages el mensaje entrante antes de grafo.
	•	Insertar en tabla messages el mensaje de respuesta después de grafo.
	5.	Modificar vector_store.py y MemoryManager para que:
	•	Al almacenar memorias incluyan user_id y session_id_db en metadata.
	•	Al buscar memorias, filtren por user_id.
	•	Devolver sólo las memorias relevantes de ese usuario.
	6.	Crear módulo curriculum.py y adaptar context_injection_node para inyectar información de nivel en el prompt de Groq.
	7.	Desarrollar nodo update_learning_stats_node para que, tras cada respuesta, extraiga nuevas palabras y errores, y actualice learning_stats en PostgreSQL.
	8.	Refactorizar should_summarize_conversation para incluir control de tokens.
	9.	Añadir tests E2E: simular llamadas a /webhook, verificar integraciones con Postgres, Qdrant y flujo del grafo.
	10.	Configurar Docker / docker-compose con servicios de Postgres y Qdrant, probar local.
	11.	Documentar en docs/architecture.md y actualizar README con ejemplos claros de interacción y explicaciones de cada módulo.
	12.	Desplegar en staging (Cloud Run o Railway), probar con un número real de WhatsApp, ajustar timeouts y límites de API key.
	13.	Refino pedagógico: nodos de feedback, mensajes de bienvenida, módulo de progresión por niveles, dashboards mínimos.

⸻

5. Conclusión ineludible
	•	Este agente ya tiene la mayoría de componentes de “holistic AI”: un grafo de flujos, persistencia de estado, memoria semántica y canal multimodal.
	•	Sin embargo, falla en la capa relacional: el sistema no vincula al “usuario” real con la memoria ni con métricas de aprendizaje.
	•	Tampoco existe un mecanismo robusto de progresión pedagógica.
	•	Se requiere reformular la implementación de get_checkpointer(), enriquecer vector_store.py con metadata de usuario, y construir el esquema relacional para que “Joi” no solo converse, sino que entienda la trayectoria de cada estudiante.
	•	Cada uno de los 13 pasos descritos arriba debe abordarse en orden preciso: primero arreglar rutas y entorno local, luego poblar la base de datos, después adaptar checkpointer y memoria, y así sucesivamente.

Esta hoja de ruta no permite atajos: si salta un paso—por ejemplo, intenta almacenar prestaciones de usuario en Qdrant sin actualizar el checkpointer— la memoria se guardará sin referencia al usuario. O si no corrige langgraph.json, el grafo no se compilará. Cada elemento es una pieza del andamiaje, y la integridad de todo depende de seguir este plan al pie de la letra.

NOTA: el archivo .env ya se encuentra configurado correctamente no necesita de crear ningun otro archivo, solo siga el plan.